{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, PunktSentenceTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "#nltk.download('punkt')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#nltk.download('wordnet')\n",
    "import itertools\n",
    "import string\n",
    "import os\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import re\n",
    "\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "\n",
    "import pandas, numpy, textblob, string\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import layers, models, optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the names and the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'D:\\\\filings_clean_withscore'\n",
    "\n",
    "files = []\n",
    "# r=root, d=directories, f = files\n",
    "for r, d, f in os.walk(path):\n",
    "    for file in f:\n",
    "        if '.txt' in file:\n",
    "            files.append(os.path.join(r, file))\n",
    "scores = []\n",
    "names = []\n",
    "for f in files:\n",
    "    scores.append(re.findall(\"_\\d_\\d_\\d_\\d\", f))\n",
    "    names.append(re.findall(\"text_10k_(.*)(?=_\\d_\\d_\\d_)\", f))\n",
    "\n",
    "names_joined = [' '.join(x) for x in names]\n",
    "text_dict  = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insert the text in a dictionary and create a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file, name in zip(files, names_joined):\n",
    "    with open(file, \"r\") as myfile:\n",
    "        text_dict[name] = myfile.read().replace(\"\\n\", \" \")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text = pd.DataFrame(text_dict.items(), columns=[\"id\", \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "del text_dict, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_joined = [' '.join(x) for x in scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "del scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create columns for the ESG scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scores_joined[0].split(\"_\")[4]\n",
    "df_text[\"total_esg\"] = 0\n",
    "df_text[\"E_score\"] = 0\n",
    "df_text[\"S_score\"] = 0\n",
    "df_text[\"G_score\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in range(len(df_text)):\n",
    "    df_text[\"total_esg\"].iloc[row] = scores_joined[row].split(\"_\")[1]\n",
    "    df_text[\"E_score\"].iloc[row] = scores_joined[row].split(\"_\")[2]\n",
    "    df_text[\"S_score\"].iloc[row] = scores_joined[row].split(\"_\")[3]\n",
    "    df_text[\"G_score\"].iloc[row] = scores_joined[row].split(\"_\")[4]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>total_esg</th>\n",
       "      <th>E_score</th>\n",
       "      <th>S_score</th>\n",
       "      <th>G_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000180_2010</th>\n",
       "      <td>10-K 1 form_10k.htm FORM 10-K FY09 form_10k.ht...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000180_2011</th>\n",
       "      <td>10-K 1 form_10k.htm FORM 10-K FY10 form_10k.ht...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           text total_esg  \\\n",
       "id                                                                          \n",
       "1000180_2010  10-K 1 form_10k.htm FORM 10-K FY09 form_10k.ht...         1   \n",
       "1000180_2011  10-K 1 form_10k.htm FORM 10-K FY10 form_10k.ht...         1   \n",
       "\n",
       "             E_score S_score G_score  \n",
       "id                                    \n",
       "1000180_2010       1       2       1  \n",
       "1000180_2011       1       2       2  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text.set_index(\"id\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>total_esg</th>\n",
       "      <th>E_score</th>\n",
       "      <th>S_score</th>\n",
       "      <th>G_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000180_2010</th>\n",
       "      <td>10-K 1 form_10k.htm FORM 10-K FY09 form_10k.ht...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000180_2011</th>\n",
       "      <td>10-K 1 form_10k.htm FORM 10-K FY10 form_10k.ht...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000180_2012</th>\n",
       "      <td>10-K 1 sndk201110-k.htm FORM 10-K FY11 SNDK 20...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000180_2013</th>\n",
       "      <td>10-K 1 sndk201210-k.htm FORM 10-K FY12 SNDK 20...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000180_2014</th>\n",
       "      <td>10-K 1 sndk201310-k.htm FORM 10-K FY13 SNDK 20...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000180_2015</th>\n",
       "      <td>10-K 1 sndk201410-k.htm FORM 10-K FY14 SNDK 20...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000228_2010</th>\n",
       "      <td>10-K 1 the10k_2009.htm THE 2009 ANNUAL 10-K RE...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000228_2011</th>\n",
       "      <td>10-K 1 the2010_10k.htm THE 2010 ANNUAL 10-K RE...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000228_2012</th>\n",
       "      <td>10-K 1 the10k_2011.htm THE 2011 ANNUAL 10-K RE...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000228_2013</th>\n",
       "      <td>10-K 1 the201210k.htm THE 2012 ANNUAL 10-K REP...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000228_2014</th>\n",
       "      <td>10-K 1 the10k_2013.htm THE 2013 ANNUAL 10-K RE...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000228_2015</th>\n",
       "      <td>10-K 1 the10k_2014.htm THE 2014 ANNUAL 10-K RE...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000228_2016</th>\n",
       "      <td>10-K 1 the10k_2015.htm THE 2015 ANNUAL 10-K RE...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000228_2017</th>\n",
       "      <td>10-K 1 the10k_2016.htm THE 2016 ANNUAL 10-K RE...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001039_2010</th>\n",
       "      <td>10-K 1 d10k.htm FORM 10-K Form 10-K Table of C...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001039_2011</th>\n",
       "      <td>10-K 1 d232174d10k.htm FORM 10-K Form 10-K Tab...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001039_2012</th>\n",
       "      <td>10-K 1 d405160d10k.htm FORM 10-K Form 10-K Tab...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001039_2013</th>\n",
       "      <td>10-K 1 fy2013_q4x10k.htm FORM 10-K FY2013_Q4_1...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001039_2014</th>\n",
       "      <td>10-K 1 fy2014_q4x10k.htm FORM 10-K FY2014_Q4_1...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001039_2015</th>\n",
       "      <td>10-K 1 fy2015_q4x10k.htm FORM 10-K 10-K UNITED...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001039_2016</th>\n",
       "      <td>10-K 1 fy2016_q4x10k.htm FORM 10-K Document UN...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001039_2017</th>\n",
       "      <td>10-K 1 fy2017_q4x10k.htm FORM 10-K Document UN...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001838_2010</th>\n",
       "      <td>10-K 1 a09-35902_110k.htm 10-K Table of Conten...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001838_2011</th>\n",
       "      <td>10-K 1 a11-2140_110k.htm 10-K Table of Content...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001838_2012</th>\n",
       "      <td>10-K 1 a12-1160_110k.htm 10-K Table of Content...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001838_2013</th>\n",
       "      <td>10-K 1 a12-29460_110k.htm 10-K Table of Conten...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001838_2014</th>\n",
       "      <td>10-K 1 a13-26010_110k.htm 10-K Table of Conten...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002517_2010</th>\n",
       "      <td>10-K 1 b82642e10vk.htm FORM 10-K e10vk Table o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002517_2011</th>\n",
       "      <td>10-K 1 b87830e10vk.htm FORM 10-K e10vk Table o...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002517_2012</th>\n",
       "      <td>10-K 1 nuan-2012930x10k.htm 10-K NUAN-2012.9.3...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96223_2017</th>\n",
       "      <td>10-K 1 luk-2016123110k.htm LEUCADIA NATIONAL C...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96943_2016</th>\n",
       "      <td>10-K 1 tfx-20151231x10k.htm 10-K 10-K SECURITI...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96943_2017</th>\n",
       "      <td>10-K 1 tfx-20161231x10k.htm 10-K Document UNIT...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97216_2014</th>\n",
       "      <td>10-K 1 tex201310-k.htm 10-K TEX 2013 10-K UNIT...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97476_2010</th>\n",
       "      <td>10-K 1 form10k.htm TEXAS INSTRUMENTS 10-K 12-3...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97476_2011</th>\n",
       "      <td>10-K 1 form10-k.htm TEXAS INSTRUMENTS 10-K 12-...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97476_2012</th>\n",
       "      <td>10-K 1 txn-12312011x10xk.htm TXN - 12.31.2011-...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97476_2013</th>\n",
       "      <td>10-K 1 txn-12312012x10xk.htm 10-K TXN - 12.31....</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97476_2014</th>\n",
       "      <td>10-K 1 txn-12312013x10xk.htm 10-K TXN - 12.31....</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97476_2015</th>\n",
       "      <td>10-K 1 txn-12312014x10xk.htm 10-K TXN - 12.31....</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97476_2016</th>\n",
       "      <td>10-K 1 txn-10k_20151231.htm 10-K txn-10k_20151...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97476_2017</th>\n",
       "      <td>10-K 1 txn-10k_20161231.htm FORM 10-K txn-10k_...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98246_2010</th>\n",
       "      <td>10-K 1 y83398e10vk.htm FORM 10-K e10vk Table o...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98246_2011</th>\n",
       "      <td>10-K 1 c09206e10vk.htm FORM 10-K Form 10-K Tab...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98246_2012</th>\n",
       "      <td>10-K 1 d285717d10k.htm FORM 10-K Form 10-K UNI...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98246_2013</th>\n",
       "      <td>10-K 1 d468956d10k.htm FORM 10-K Form 10-K UNI...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98246_2014</th>\n",
       "      <td>10-K 1 tif-2014131x10k.htm 10-K TIF-2014.1.31-...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98246_2015</th>\n",
       "      <td>10-K 1 tif-2015131x10k.htm 10-K TIF-2015.1.31-...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98246_2016</th>\n",
       "      <td>10-K 1 tif-2016131x10k.htm 10-K 10-K Table of ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98246_2017</th>\n",
       "      <td>10-K 1 tif-2017131x10k.htm 10-K Document Table...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98362_2012</th>\n",
       "      <td>10-K 1 d269602d10k.htm FORM 10-K FORM 10-K Tab...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98362_2013</th>\n",
       "      <td>10-K 1 tkr-20121231x10k.htm 10-K TKR-2012.12.3...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98362_2015</th>\n",
       "      <td>10-K 1 tkr10k123114.htm 10-K TKR 10K 12.31.14 ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98362_2017</th>\n",
       "      <td>10-K 1 tkr10k123116.htm 10-K Document false --...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99780_2010</th>\n",
       "      <td>10-K 1 d71017e10vk.htm FORM 10-K e10vk Table o...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99780_2011</th>\n",
       "      <td>10-K 1 d78691e10vk.htm FORM 10-K e10vk Table o...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99780_2012</th>\n",
       "      <td>10-K 1 d261475d10k.htm FORM 10-K Form 10-K Tab...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99780_2013</th>\n",
       "      <td>10-K 1 trn1231201210k-discops.htm 10-K TRN 12....</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99780_2015</th>\n",
       "      <td>10-K 1 trn1231201410k.htm 10-K TRN 12.31.2014 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99780_2017</th>\n",
       "      <td>10-K 1 trn1231201610k.htm 10-K Document UNITED...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3770 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           text total_esg  \\\n",
       "id                                                                          \n",
       "1000180_2010  10-K 1 form_10k.htm FORM 10-K FY09 form_10k.ht...         1   \n",
       "1000180_2011  10-K 1 form_10k.htm FORM 10-K FY10 form_10k.ht...         1   \n",
       "1000180_2012  10-K 1 sndk201110-k.htm FORM 10-K FY11 SNDK 20...         1   \n",
       "1000180_2013  10-K 1 sndk201210-k.htm FORM 10-K FY12 SNDK 20...         1   \n",
       "1000180_2014  10-K 1 sndk201310-k.htm FORM 10-K FY13 SNDK 20...         2   \n",
       "1000180_2015  10-K 1 sndk201410-k.htm FORM 10-K FY14 SNDK 20...         2   \n",
       "1000228_2010  10-K 1 the10k_2009.htm THE 2009 ANNUAL 10-K RE...         2   \n",
       "1000228_2011  10-K 1 the2010_10k.htm THE 2010 ANNUAL 10-K RE...         1   \n",
       "1000228_2012  10-K 1 the10k_2011.htm THE 2011 ANNUAL 10-K RE...         1   \n",
       "1000228_2013  10-K 1 the201210k.htm THE 2012 ANNUAL 10-K REP...         1   \n",
       "1000228_2014  10-K 1 the10k_2013.htm THE 2013 ANNUAL 10-K RE...         2   \n",
       "1000228_2015  10-K 1 the10k_2014.htm THE 2014 ANNUAL 10-K RE...         2   \n",
       "1000228_2016  10-K 1 the10k_2015.htm THE 2015 ANNUAL 10-K RE...         2   \n",
       "1000228_2017  10-K 1 the10k_2016.htm THE 2016 ANNUAL 10-K RE...         2   \n",
       "1001039_2010  10-K 1 d10k.htm FORM 10-K Form 10-K Table of C...         2   \n",
       "1001039_2011  10-K 1 d232174d10k.htm FORM 10-K Form 10-K Tab...         1   \n",
       "1001039_2012  10-K 1 d405160d10k.htm FORM 10-K Form 10-K Tab...         1   \n",
       "1001039_2013  10-K 1 fy2013_q4x10k.htm FORM 10-K FY2013_Q4_1...         1   \n",
       "1001039_2014  10-K 1 fy2014_q4x10k.htm FORM 10-K FY2014_Q4_1...         1   \n",
       "1001039_2015  10-K 1 fy2015_q4x10k.htm FORM 10-K 10-K UNITED...         1   \n",
       "1001039_2016  10-K 1 fy2016_q4x10k.htm FORM 10-K Document UN...         2   \n",
       "1001039_2017  10-K 1 fy2017_q4x10k.htm FORM 10-K Document UN...         1   \n",
       "1001838_2010  10-K 1 a09-35902_110k.htm 10-K Table of Conten...         0   \n",
       "1001838_2011  10-K 1 a11-2140_110k.htm 10-K Table of Content...         1   \n",
       "1001838_2012  10-K 1 a12-1160_110k.htm 10-K Table of Content...         0   \n",
       "1001838_2013  10-K 1 a12-29460_110k.htm 10-K Table of Conten...         1   \n",
       "1001838_2014  10-K 1 a13-26010_110k.htm 10-K Table of Conten...         1   \n",
       "1002517_2010  10-K 1 b82642e10vk.htm FORM 10-K e10vk Table o...         1   \n",
       "1002517_2011  10-K 1 b87830e10vk.htm FORM 10-K e10vk Table o...         0   \n",
       "1002517_2012  10-K 1 nuan-2012930x10k.htm 10-K NUAN-2012.9.3...         0   \n",
       "...                                                         ...       ...   \n",
       "96223_2017    10-K 1 luk-2016123110k.htm LEUCADIA NATIONAL C...         1   \n",
       "96943_2016    10-K 1 tfx-20151231x10k.htm 10-K 10-K SECURITI...         1   \n",
       "96943_2017    10-K 1 tfx-20161231x10k.htm 10-K Document UNIT...         0   \n",
       "97216_2014    10-K 1 tex201310-k.htm 10-K TEX 2013 10-K UNIT...         0   \n",
       "97476_2010    10-K 1 form10k.htm TEXAS INSTRUMENTS 10-K 12-3...         1   \n",
       "97476_2011    10-K 1 form10-k.htm TEXAS INSTRUMENTS 10-K 12-...         0   \n",
       "97476_2012    10-K 1 txn-12312011x10xk.htm TXN - 12.31.2011-...         0   \n",
       "97476_2013    10-K 1 txn-12312012x10xk.htm 10-K TXN - 12.31....         0   \n",
       "97476_2014    10-K 1 txn-12312013x10xk.htm 10-K TXN - 12.31....         0   \n",
       "97476_2015    10-K 1 txn-12312014x10xk.htm 10-K TXN - 12.31....         0   \n",
       "97476_2016    10-K 1 txn-10k_20151231.htm 10-K txn-10k_20151...         0   \n",
       "97476_2017    10-K 1 txn-10k_20161231.htm FORM 10-K txn-10k_...         0   \n",
       "98246_2010    10-K 1 y83398e10vk.htm FORM 10-K e10vk Table o...         2   \n",
       "98246_2011    10-K 1 c09206e10vk.htm FORM 10-K Form 10-K Tab...         1   \n",
       "98246_2012    10-K 1 d285717d10k.htm FORM 10-K Form 10-K UNI...         1   \n",
       "98246_2013    10-K 1 d468956d10k.htm FORM 10-K Form 10-K UNI...         1   \n",
       "98246_2014    10-K 1 tif-2014131x10k.htm 10-K TIF-2014.1.31-...         2   \n",
       "98246_2015    10-K 1 tif-2015131x10k.htm 10-K TIF-2015.1.31-...         2   \n",
       "98246_2016    10-K 1 tif-2016131x10k.htm 10-K 10-K Table of ...         2   \n",
       "98246_2017    10-K 1 tif-2017131x10k.htm 10-K Document Table...         2   \n",
       "98362_2012    10-K 1 d269602d10k.htm FORM 10-K FORM 10-K Tab...         2   \n",
       "98362_2013    10-K 1 tkr-20121231x10k.htm 10-K TKR-2012.12.3...         2   \n",
       "98362_2015    10-K 1 tkr10k123114.htm 10-K TKR 10K 12.31.14 ...         2   \n",
       "98362_2017    10-K 1 tkr10k123116.htm 10-K Document false --...         1   \n",
       "99780_2010    10-K 1 d71017e10vk.htm FORM 10-K e10vk Table o...         0   \n",
       "99780_2011    10-K 1 d78691e10vk.htm FORM 10-K e10vk Table o...         0   \n",
       "99780_2012    10-K 1 d261475d10k.htm FORM 10-K Form 10-K Tab...         0   \n",
       "99780_2013    10-K 1 trn1231201210k-discops.htm 10-K TRN 12....         0   \n",
       "99780_2015    10-K 1 trn1231201410k.htm 10-K TRN 12.31.2014 ...         0   \n",
       "99780_2017    10-K 1 trn1231201610k.htm 10-K Document UNITED...         0   \n",
       "\n",
       "             E_score S_score G_score  \n",
       "id                                    \n",
       "1000180_2010       1       2       1  \n",
       "1000180_2011       1       2       2  \n",
       "1000180_2012       1       2       1  \n",
       "1000180_2013       1       2       1  \n",
       "1000180_2014       2       1       2  \n",
       "1000180_2015       2       1       2  \n",
       "1000228_2010       2       1       2  \n",
       "1000228_2011       1       2       1  \n",
       "1000228_2012       1       2       1  \n",
       "1000228_2013       1       1       1  \n",
       "1000228_2014       1       2       2  \n",
       "1000228_2015       1       2       2  \n",
       "1000228_2016       2       2       2  \n",
       "1000228_2017       2       1       2  \n",
       "1001039_2010       2       1       2  \n",
       "1001039_2011       1       2       0  \n",
       "1001039_2012       1       2       1  \n",
       "1001039_2013       1       1       1  \n",
       "1001039_2014       0       2       1  \n",
       "1001039_2015       0       1       1  \n",
       "1001039_2016       1       2       1  \n",
       "1001039_2017       1       1       1  \n",
       "1001838_2010       0       1       0  \n",
       "1001838_2011       1       2       0  \n",
       "1001838_2012       1       2       0  \n",
       "1001838_2013       1       2       1  \n",
       "1001838_2014       1       2       2  \n",
       "1002517_2010       0       1       2  \n",
       "1002517_2011       0       0       0  \n",
       "1002517_2012       0       0       0  \n",
       "...              ...     ...     ...  \n",
       "96223_2017         1       0       1  \n",
       "96943_2016         0       0       0  \n",
       "96943_2017         0       0       0  \n",
       "97216_2014         0       0       0  \n",
       "97476_2010         1       1       1  \n",
       "97476_2011         0       0       0  \n",
       "97476_2012         0       0       1  \n",
       "97476_2013         0       1       1  \n",
       "97476_2014         0       0       1  \n",
       "97476_2015         0       0       0  \n",
       "97476_2016         0       0       0  \n",
       "97476_2017         0       0       0  \n",
       "98246_2010         2       2       2  \n",
       "98246_2011         2       1       0  \n",
       "98246_2012         2       1       0  \n",
       "98246_2013         2       1       0  \n",
       "98246_2014         2       2       0  \n",
       "98246_2015         2       2       1  \n",
       "98246_2016         2       2       1  \n",
       "98246_2017         2       2       1  \n",
       "98362_2012         2       2       2  \n",
       "98362_2013         1       2       1  \n",
       "98362_2015         2       2       1  \n",
       "98362_2017         2       1       0  \n",
       "99780_2010         1       0       0  \n",
       "99780_2011         0       1       0  \n",
       "99780_2012         0       0       1  \n",
       "99780_2013         0       1       1  \n",
       "99780_2015         0       1       1  \n",
       "99780_2017         0       0       0  \n",
       "\n",
       "[3770 rows x 5 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "documents = []\n",
    "\n",
    "stemmer = WordNetLemmatizer()\n",
    "\n",
    "for sen in range(0, len(df_text)):  \n",
    "    # Remove all the special characters\n",
    "    document = re.sub(r'\\W', ' ', str(df_text[\"text\"][sen]))\n",
    "\n",
    "    # remove all single characters\n",
    "    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "\n",
    "    # Remove single characters from the start\n",
    "    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
    "\n",
    "    # Substituting multiple spaces with single space\n",
    "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "\n",
    "    # Removing prefixed 'b'\n",
    "    document = re.sub(r'^b\\s+', '', document)\n",
    "\n",
    "    # Converting to Lowercase\n",
    "    document = document.lower()\n",
    "\n",
    "    # Lemmatization\n",
    "    document = document.split()\n",
    "\n",
    "    document = [stemmer.lemmatize(word) for word in document]\n",
    "    document = ' '.join(document)\n",
    "\n",
    "    documents.append(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insert the preprocessed documents in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row_t in range(len(df_text)):\n",
    "    df_text[\"text\"].iloc[row_t] = documents[row_t]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into training and validation datasets \n",
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(df_text['text'], df_text['total_esg'])\n",
    "\n",
    "# label encode the target variable \n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "valid_y = encoder.fit_transform(valid_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a count vectorizer object \n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "count_vect.fit(df_text['text'])\n",
    "\n",
    "# transform the training and validation data using count vectorizer object\n",
    "xtrain_count =  count_vect.transform(train_x)\n",
    "xvalid_count =  count_vect.transform(valid_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Term Frequency - Inverse Document Frequency (TF-IDF)\n",
    "* Word\n",
    "* ngrams\n",
    "* Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word level tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
    "tfidf_vect.fit(df_text['text'])\n",
    "xtrain_tfidf =  tfidf_vect.transform(train_x)\n",
    "xvalid_tfidf =  tfidf_vect.transform(valid_x)\n",
    "\n",
    "# ngram level tf-idf \n",
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_vect_ngram.fit(df_text['text'])\n",
    "xtrain_tfidf_ngram =  tfidf_vect_ngram.transform(train_x)\n",
    "xvalid_tfidf_ngram =  tfidf_vect_ngram.transform(valid_x)\n",
    "\n",
    "# characters level tf-idf\n",
    "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_vect_ngram_chars.fit(df_text['text'])\n",
    "xtrain_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(train_x) \n",
    "xvalid_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(valid_x) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pre-trained word-embedding vectors \n",
    "embeddings_index = {}\n",
    "for i, line in enumerate(open('crawl-300d-2M.vec', encoding='utf-8')):\n",
    "    values = line.split()\n",
    "    embeddings_index[values[0]] = numpy.asarray(values[1:], dtype='float32')\n",
    "\n",
    "# create a tokenizer \n",
    "token = text.Tokenizer()\n",
    "token.fit_on_texts(df_text['text'])\n",
    "word_index = token.word_index\n",
    "\n",
    "# convert text to sequence of tokens and pad them to ensure equal length vectors \n",
    "train_seq_x = sequence.pad_sequences(token.texts_to_sequences(train_x), maxlen=70)\n",
    "valid_seq_x = sequence.pad_sequences(token.texts_to_sequences(valid_x), maxlen=70)\n",
    "\n",
    "# create token-embedding mapping\n",
    "embedding_matrix = numpy.zeros((len(word_index) + 1, 300))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering\n",
    "## Groups of words need to be added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text['char_count'] = df_text['text'].apply(len)\n",
    "df_text['word_count'] = df_text['text'].apply(lambda x: len(x.split()))\n",
    "df_text['word_density'] = df_text['char_count'] / (df_text['word_count']+1)\n",
    "df_text['punctuation_count'] = df_text['text'].apply(lambda x: len(\"\".join(_ for _ in x if _ in string.punctuation))) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d = pd.DataFrame(xtrain_tfidf_ngram_chars.toarray(), columns=tfidf_vect_ngram_chars.get_feature_names())\n",
    "#train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Hella\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk.download(\"averaged_perceptron_tagger\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Dirichlet Allocation (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a LDA Model\n",
    "lda_model = decomposition.LatentDirichletAllocation(n_components=20, learning_method='online', max_iter=20)\n",
    "X_topics = lda_model.fit_transform(xtrain_count)\n",
    "topic_word = lda_model.components_ \n",
    "vocab = count_vect.get_feature_names()\n",
    "\n",
    "# view the topic models\n",
    "n_top_words = 10\n",
    "topic_summaries = []\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = numpy.array(vocab)[numpy.argsort(topic_dist)][:-(n_top_words+1):-1]\n",
    "    topic_summaries.append(' '.join(topic_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    \n",
    "    if is_neural_net:\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "    \n",
    "    return metrics.accuracy_score(predictions, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rnn_lstm():\n",
    "    # Add an Input Layer\n",
    "    input_layer = layers.Input((70, ))\n",
    "\n",
    "    # Add the word embedding Layer\n",
    "    embedding_layer = layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)(input_layer)\n",
    "    embedding_layer = layers.SpatialDropout1D(0.3)(embedding_layer)\n",
    "\n",
    "    # Add the LSTM Layer\n",
    "    lstm_layer = layers.LSTM(100)(embedding_layer)\n",
    "\n",
    "    # Add the output Layers\n",
    "    output_layer1 = layers.Dense(50, activation=\"relu\")(lstm_layer)\n",
    "    output_layer1 = layers.Dropout(0.25)(output_layer1)\n",
    "    output_layer2 = layers.Dense(1, activation=\"sigmoid\")(output_layer1)\n",
    "\n",
    "    # Compile the model\n",
    "    model = models.Model(inputs=input_layer, outputs=output_layer2)\n",
    "    model.compile(optimizer=optimizers.Adam(), loss='binary_crossentropy')\n",
    "    \n",
    "    return model\n",
    "\n",
    "classifier = create_rnn_lstm()\n",
    "accuracy = train_model(classifier, train_seq_x, train_y, valid_seq_x, is_neural_net=True)\n",
    "print \"RNN-LSTM, Word Embeddings\",  accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
